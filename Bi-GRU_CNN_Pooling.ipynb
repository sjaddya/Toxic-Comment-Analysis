{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "np.random.seed(32)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras.models import Model, load_model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras import backend as K\n",
    "from keras.engine import InputSpec, Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(cmnt_text, clean_wiki_tokens = True):\n",
    "    cmnt_text = cmnt_text.lower()\n",
    "    #removing links\n",
    "    cmnt_text = re.sub(r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\", \"\", cmnt_text)\n",
    "    #removing IP addresses\n",
    "    cmnt_text = re.sub(r\"(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}\", \"\", cmnt_text)\n",
    "    \n",
    "    if clean_wiki_tokens:\n",
    "        #removing images\n",
    "        cmnt_text = re.sub(r\"image:[a-zA-Z0-9]*\\.jpg\", \" \", cmnt_text)\n",
    "        cmnt_text = re.sub(r\"image:[a-zA-Z0-9]*\\.png\", \" \", cmnt_text)\n",
    "        cmnt_text = re.sub(r\"image:[a-zA-Z0-9]*\\.gif\", \" \", cmnt_text)\n",
    "        cmnt_text = re.sub(r\"image:[a-zA-Z0-9]*\\.bmp\", \" \", cmnt_text)\n",
    "        \n",
    "        #removing CSS\n",
    "        cmnt_text = re.sub(r\"#([A-Fa-f0-9]{6}|[A-Fa-f0-9]{3})\", \" \",cmnt_text)\n",
    "        cmnt_text = re.sub(r\"\\{\\|[^\\}]*\\|\\}\", \" \", cmnt_text)\n",
    "        \n",
    "        #removing templates\n",
    "        cmnt_text = re.sub(r\"\\[?\\[user:.*\\]\", \" \", cmnt_text)\n",
    "        cmnt_text = re.sub(r\"\\[?\\[wikipedia:.*\\]\", \" \", cmnt_text)\n",
    "        cmnt_text = re.sub(r\"\\[?\\[special:.*\\]\", \" \", cmnt_text)\n",
    "        cmnt_text = re.sub(r\"\\[?\\[category:.*\\]\", \" \", cmnt_text)\n",
    "        \n",
    "    cmnt_text = re.sub(r\"what's\", \"what is \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\'s\", \" \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\'ve\", \" have \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"can't\", \" cannot \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"n't\", \" not \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"i'm\", \" i am \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\'m\", \" i am \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\'re\", \" are \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\'d\", \" would \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\'ll\", \" will \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\",\", \" \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\.\", \" \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"!\", \" ! \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\/\", \" \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\?\", \" ? \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\!\", \" ! \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\\"\", \" \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\^\", \" ^ \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\+\", \" + \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\-\", \" - \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\=\", \" = \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"'\", \" \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", cmnt_text)\n",
    "    cmnt_text = re.sub(r\":\", \" : \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\" e g \", \" eg \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\" b g \", \" bg \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\" u s \", \" american \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\0s\", \"0\", cmnt_text)\n",
    "    cmnt_text = re.sub(r\" 9 11 \", \"911\", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"e - mail\", \"email\", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"j k\", \"jk\", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\s{2,}\", \" \", cmnt_text)\n",
    "    cmnt_text = re.sub(r\"\\n\", \" \", cmnt_text)\n",
    "    \n",
    "        \n",
    "    return(cmnt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Loads data and returns train, val, and test splits\n",
    "    \"\"\"\n",
    "    # Load the train dataset\n",
    "    df = pd.read_csv(\"train.csv\")\n",
    "    \n",
    "    # Clean the text\n",
    "    df['comment_text'] = df.comment_text.apply(lambda x : clean_text(x))\n",
    "    \n",
    "    list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "    y = df[list_classes].values\n",
    "    df[\"comment_text\"].fillna(\"no comment\")\n",
    "\n",
    "    # split for cross-validation (train-70%, validation 15% and test 15%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.3, random_state=123)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = \"glove.840B.300d.txt\"\n",
    "embed_size = 300\n",
    "max_features = 100000\n",
    "max_len = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69965</th>\n",
       "      <td>bb274cdd98b173e5</td>\n",
       "      <td>thanks anyway there no consensus for retitling...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95303</th>\n",
       "      <td>fecd68f4bb1a159a</td>\n",
       "      <td>sorry i misunderstood the point you were tryin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41327</th>\n",
       "      <td>6e3710fd4050058b</td>\n",
       "      <td>this is great i will address these in the next...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95363</th>\n",
       "      <td>fef6d1e43fbdd330</td>\n",
       "      <td>flemish ? pardon my ignorance but i have no id...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142270</th>\n",
       "      <td>f8f74f60e453668e</td>\n",
       "      <td>sally nicholls regarding this edit—since when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "69965   bb274cdd98b173e5  thanks anyway there no consensus for retitling...   \n",
       "95303   fecd68f4bb1a159a  sorry i misunderstood the point you were tryin...   \n",
       "41327   6e3710fd4050058b  this is great i will address these in the next...   \n",
       "95363   fef6d1e43fbdd330  flemish ? pardon my ignorance but i have no id...   \n",
       "142270  f8f74f60e453668e  sally nicholls regarding this edit—since when ...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "69965       0             0        0       0       0              0  \n",
       "95303       0             0        0       0       0              0  \n",
       "41327       0             0        0       0       0              0  \n",
       "95363       0             0        0       0       0              0  \n",
       "142270      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_train = X_train[\"comment_text\"]\n",
    "raw_text_valid = X_val[\"comment_text\"]\n",
    "raw_text_test = X_test[\"comment_text\"]\n",
    "\n",
    "tk = Tokenizer(num_words = max_features, lower = True)\n",
    "tk.fit_on_texts(raw_text_train)\n",
    "X_train[\"comment_seq\"] = tk.texts_to_sequences(raw_text_train)\n",
    "X_val[\"comment_seq\"] = tk.texts_to_sequences(raw_text_valid)\n",
    "X_test[\"comment_seq\"] = tk.texts_to_sequences(raw_text_test)\n",
    "\n",
    "X_train = pad_sequences(X_train.comment_seq, maxlen = max_len)\n",
    "X_val = pad_sequences(X_val.comment_seq, maxlen = max_len)\n",
    "X_test = pad_sequences(X_test.comment_seq, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111699, 150)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tk.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n",
    "\n",
    "file_path = \"bi_gru_cnn.hdf5\"\n",
    "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
    "                              save_best_only = True, mode = \"min\")\n",
    "ra_val = RocAucEvaluation(validation_data=(X_val, y_val), interval = 1)\n",
    "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
    "\n",
    "def build_model(lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0):\n",
    "    inp = Input(shape = (max_len,))\n",
    "    x = Embedding(max_features, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
    "    x = SpatialDropout1D(dr)(x)\n",
    "\n",
    "    x = Bidirectional(GRU(units, return_sequences = True))(x)\n",
    "    x = Conv1D(64, kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    x = concatenate([avg_pool, max_pool])\n",
    "\n",
    "    x = Dense(6, activation = \"sigmoid\")(x)\n",
    "    model = Model(inputs = inp, outputs = x)\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
    "    model.summary()\n",
    "    history = model.fit(X_train, y_train, batch_size = 128, epochs = 4, validation_data = (X_val, y_val), \n",
    "                        verbose = 1, callbacks = [check_point, early_stop])\n",
    "    model = load_model(file_path)\n",
    "    return model\n",
    "\n",
    "''', history'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sjaddya/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/sjaddya/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 150, 300)     30000000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 150, 300)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 150, 256)     329472      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 149, 64)      32832       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 64)           0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            774         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 30,363,078\n",
      "Trainable params: 363,078\n",
      "Non-trainable params: 30,000,000\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/sjaddya/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/sjaddya/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 111699 samples, validate on 23936 samples\n",
      "Epoch 1/4\n",
      "111699/111699 [==============================] - 855s 8ms/step - loss: 0.0569 - acc: 0.9800 - val_loss: 0.0429 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04289, saving model to bi_gru_cnn.hdf5\n",
      "Epoch 2/4\n",
      " 62976/111699 [===============>..............] - ETA: 5:46 - loss: 0.0437 - acc: 0.9832"
     ]
    }
   ],
   "source": [
    "model= build_model(lr = 1e-3, lr_d = 0, units = 128, dr = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sjaddya/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/sjaddya/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/sjaddya/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/sjaddya/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 111699 samples, validate on 23936 samples\n",
      "Epoch 1/4\n",
      "111699/111699 [==============================] - 862s 8ms/step - loss: 0.0572 - acc: 0.9800 - val_loss: 0.0429 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04285, saving model to bi_gru_cnn.hdf5\n",
      "Epoch 2/4\n",
      "111699/111699 [==============================] - 875s 8ms/step - loss: 0.0435 - acc: 0.9832 - val_loss: 0.0421 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04285 to 0.04207, saving model to bi_gru_cnn.hdf5\n",
      "Epoch 3/4\n",
      "111699/111699 [==============================] - 892s 8ms/step - loss: 0.0404 - acc: 0.9842 - val_loss: 0.0420 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04207 to 0.04201, saving model to bi_gru_cnn.hdf5\n",
      "Epoch 4/4\n",
      "111699/111699 [==============================] - 907s 8ms/step - loss: 0.0378 - acc: 0.9852 - val_loss: 0.0426 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04201\n",
      "23936/23936 [==============================] - 74s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model= build_model(lr = 1e-3, lr_d = 0, units = 128, dr = 0.2)\n",
    "pred = model.predict(X_test, batch_size = 1024, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.2114695e-02, 3.8266182e-05, 8.1378222e-04, 4.3761730e-04,\n",
       "        6.8765879e-03, 4.9948692e-05],\n",
       "       [1.0837197e-02, 4.1455030e-05, 2.6944280e-04, 2.9832125e-05,\n",
       "        1.7177463e-03, 2.3454428e-05],\n",
       "       [1.0226667e-03, 6.3478947e-06, 1.4722347e-04, 2.9087067e-05,\n",
       "        1.6349554e-04, 6.8634748e-05],\n",
       "       ...,\n",
       "       [9.5941347e-01, 3.8549602e-03, 2.6236752e-01, 3.8476288e-03,\n",
       "        7.5894535e-01, 1.1804968e-02],\n",
       "       [2.4146676e-02, 6.6459179e-06, 9.4228983e-04, 6.1690807e-06,\n",
       "        2.0054877e-03, 7.0929527e-06],\n",
       "       [2.1992624e-03, 6.2376261e-05, 1.6245246e-04, 9.5754862e-05,\n",
       "        5.5021048e-04, 7.9855323e-04]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[21165   510]\n",
      " [  357  1904]]\n",
      "f1_score:  0.8145454545454546\n",
      "Accuracy:  0.9637784090909091\n",
      "recall_score:  0.8421052631578947\n",
      "\n",
      "\n",
      "1\n",
      "[[23603    90]\n",
      " [  133   110]]\n",
      "f1_score:  0.4966139954853273\n",
      "Accuracy:  0.9906834893048129\n",
      "recall_score:  0.45267489711934156\n",
      "\n",
      "\n",
      "2\n",
      "[[22546   144]\n",
      " [  256   990]]\n",
      "f1_score:  0.8319327731092437\n",
      "Accuracy:  0.9832887700534759\n",
      "recall_score:  0.7945425361155698\n",
      "\n",
      "\n",
      "3\n",
      "[[23847    27]\n",
      " [   38    24]]\n",
      "f1_score:  0.4247787610619469\n",
      "Accuracy:  0.9972844251336899\n",
      "recall_score:  0.3870967741935484\n",
      "\n",
      "\n",
      "4\n",
      "[[22468   324]\n",
      " [  225   919]]\n",
      "f1_score:  0.770004189359028\n",
      "Accuracy:  0.9770638368983957\n",
      "recall_score:  0.8033216783216783\n",
      "\n",
      "\n",
      "5\n",
      "[[23723     8]\n",
      " [  181    24]]\n",
      "f1_score:  0.20253164556962028\n",
      "Accuracy:  0.9921039438502673\n",
      "recall_score:  0.11707317073170732\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "p = pred.round()\n",
    "label_names = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "for i in range(6):\n",
    "    print(i)\n",
    "    print(confusion_matrix(y_test[:, i], p[:, i]))\n",
    "    print(\"f1_score: \",f1_score(y_test[:, i], p[:, i]))\n",
    "    print(\"Accuracy: \",accuracy_score(y_test[:, i], p[:, i]))\n",
    "    print(\"recall_score: \",recall_score(y_test[:, i], p[:, i]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Accuracy 98.39\n",
    "## Test f1_score 59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Accuracy 98.42\n",
    "\n",
    "## Validation Accuracy 98.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
